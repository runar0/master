
Split deadlines:
 - 20. May Wednesday: Complete result section (Partitioning and new sensitivity), ready for final delivery.
 - 22. May Friday: Complete introduction. Finish restructuring of algorithms and implementation.
 - 26. May Tuesday: Complete framework (Text and diagrams)



General TODO:

- Introduction: 
  - Introduce cache partitioning algorithms in intro
  - Common patterns from algorithms into intro
  - Intro must introduce our contribution

- Algorithms:
  - Remove common patterns, algorithms is now just that
  - Split partitioning and non algorithms, 4/6 split?

  - Add missing figures, all up to UCP is good
     - Before creating more figures we should plan a access pattern that can be used in all cases, and will show all behaviour
        This makes it easier to follow, and it makes it easier to see differences between algorithms
     - The split between algorithms will make it so that one needs a stream with multiple cores while the other does not care, this makes the grouping logical
     - Make the figures more compact

- Implementation -> Framework.
  - Move selection of Sniper to framework
    - (Update comparison of SimFlex and SimPoint, make it more explicit, should only need one or two sentences)
  - Document sniper structure
  - Document our changes in Sniper
    - Create a block diagram showing the relationships between a core, cache_ctrl, cache, cache set info and finally cache set.
    - (In potentially a second graph) show the  inheritence three from cache_set and cache_set_info into our implemented algorithms.

  - Document implemented algorithms

- Methodology:
  - Remove Sniper selection
  - Update L3 cache profiles, we need even more for the additional sensitivity analysis.
     - We need one 2MB profile, we can borrow the 1MB and .5MB from the l2 model.


- Results:
  - Split into two sections, one of the main experiment and one for the additional sensitivity analysis
  - In main experiment plot CABW data per workload, attempt to investigate how UCP is able to increase misses while also increasing performance.
     - When doing this; make the STP plot a stacked bar graph so the speedup of each individual benchmark is visible. 
       - Figure out how to represent speedups of less than 1 (i.e. slowdown), needs to be obvious somehow.
  - Sensitivity sections:
  	- Two additional experiments:
  	   - Vary L3 size for 4-core workloads
  	   - Vary memory bandwidth for 4-core workloads
  	   - We expect an increase in performance increase when lowering L3 size, as we're putting more preassure on the algorithms
  		 - We might need to do some combination experiments, where we vary both bus and l3, if we're not seeing much of a difference.


General:
   - Ofc we need to do a complete read-through by the end, spotting typos and miss corrected words.
   - Avoid full page illustrations, as this breaks the flow of the text. For results this is less important.
   - Re-read Jahres comments, make sure we have addressed obvious weaknesses.
   - All Sniper core should be committed, commented and made obvious. Compress it for delivery, it will be handed in alongside the pdf.



Specific, and prioritized, task:


Leave for later:
- UCP: Create figure, LRU template. Start with two cores and a 1-3 pyhsical division 2-2 allocations, do two inserts and end at 2-2
- PIPP: Do the same example as in UCP but with PIPP insertion rules?
- CLU: Create a dummy plot showing a LRU and BIP utility graph, write a short paragraph detailing how the algorithm selects between LRU and BIP given two sample allocations.

- Fill out discussion, conclusion and future work 
- Comment and clean code, make sure everything is merged correctly to development branch, preparing for handin