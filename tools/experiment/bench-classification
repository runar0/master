#!/usr/bin/env python

# Automatic benchmark classification based on a --experiement-classification run

import argparse
import os
import numpy as np
from matplotlib import pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import axes3d
import scipy.interpolate as interpolate

from os import path
from sys import exit
import collections

from build import profiles
from benchmarks import benchmark_sets

def extract_ipc(filename):
	ipc = None
	with open(filename) as f:
		for line in f:
			line = line.split(' = ')
			if line[0] == 'ipc':
				ipc = float(line[1])
	return ipc


parser = argparse.ArgumentParser(description='Perform a automatic benchmark classification')
parser.add_argument('--dir', default='.', help='Experiment run directory')
parser.add_argument('--out', default='_figures/', help='Figure output directory')

args = parser.parse_args()

if not path.exists(args.dir):
	exit('Run directory %s does not exist!' % args.dir)

if not path.exists(args.out):
	os.makedirs(args.out)
	print 'Created output directory %s' % args.out


rundir = path.realpath(args.dir)

benchmarks = {}

for subdir, dirs, files in os.walk(rundir):
	for name in dirs:		
		# TODO: For now we only handle 100M runs, we should handle them all and report any differences!
		if name.find('.250M.') == -1:
			continue

		parts = name.split('.')

		if parts[0].find('-') != -1:
			exit("Expected only benchmark runs in classification experiment, found workload run %s" % parts[0])

		if parts[0] not in benchmarks:
			benchmarks[parts[0]] = {}


		membus = l3 = None
		for part in parts:
			config = part.replace('_', '.').split('-')
			if config[0] == "membus":
				if config[1] != "C":
					exit('Expecting all runs to be with classification profiles, unexpected membus profile %s' % part)
				membus = config[2]

			if config[0] == "l3":
				if config[1] != "C":
					exit('Expecting all runs to be with classification profiles, unexpected l3 profile %s' % part)
				l3 = config[2]

		if membus not in benchmarks[parts[0]]:
			benchmarks[parts[0]][membus] = {}
		benchmarks[parts[0]][membus][l3] = extract_ipc(path.join(rundir, name, 'stats-benchmark-0.txt'))


# Sort data
for benchmark in benchmarks:
	for membus in benchmarks[benchmark]:
		benchmarks[benchmark][membus] = collections.OrderedDict(sorted(benchmarks[benchmark][membus].items(), reverse=True))
	benchmarks[benchmark] = collections.OrderedDict(sorted(benchmarks[benchmark].items(), reverse=True))

# Create surface plots showing relative IPC difference
for benchmark in benchmarks:
	x = []
	y = []
	z = []

	base = float(benchmarks[benchmark]['12.8']['4.00'])
	for membus in benchmarks[benchmark]:
		for cache in benchmarks[benchmark][membus]:
			x.append(float(membus))
			y.append(float(cache))
			z.append(float(benchmarks[benchmark][membus][cache])/base)

	x = np.array(x, dtype=np.float)
	y = np.array(y, dtype=np.float)
	z = np.array(z, dtype=np.float)

	fig = plt.figure()
	ax = fig.add_subplot(111, projection='3d')

	X,Y = np.meshgrid(x,y)
	Z = interpolate.griddata((x, y), z, (X, Y), method='nearest')

	ax.plot_surface(X, Y, Z, rstride=1, cstride=1)

	plt.xticks(np.array(benchmarks[benchmark].keys(), dtype=np.float))
	plt.yticks(np.array(benchmarks[benchmark]['12.8'].keys(), dtype=np.float))


	plt.suptitle('Sensitivity analysis of %s' % benchmark)
	ax.set_xlabel('Membus speed (GB/s)')
	ax.set_ylabel('L3 Cache size (MB)')
	ax.set_zlabel('IPC (Relative to 12.8GB/s 4MB)')

	ax.set_zlim3d(0.4, 1.1)

	ax.view_init(elev=10., azim=45+180)

	plt.savefig(path.join(args.out, '%s.png' % (benchmark)), frameon=False, bbox_inches='tight')
	plt.clf()

classified = { 'co': [], 'bw': [], 'ca': [], 'ca-bw': []}
# Classify benchmarks
for benchmark in benchmarks:
	print "Benchmark: %s" % benchmark

	values = []
	for membus in benchmarks[benchmark]:
		prev = None
		for l3size in benchmarks[benchmark][membus]:
			if prev != None:
				values.append(benchmarks[benchmark][membus][l3size]/benchmarks[benchmark][membus][prev])
			prev = l3size

	meanCacheDiff = np.average(values)
	stdCacheDiff = np.std(values)
	cacheSense = meanCacheDiff <= 0.965 if stdCacheDiff < 0.114 else meanCacheDiff <= 0.87

	print "\tCache%s\t: MEAN: %.3f STD: %.3f" % ("*" if cacheSense else " ", meanCacheDiff, stdCacheDiff)

	values = []
	for l3size in benchmarks[benchmark]['12.8']:
		prev = None
		for membus in benchmarks[benchmark]:
			if prev != None:
				values.append(benchmarks[benchmark][membus][l3size]/benchmarks[benchmark][prev][l3size])
			prev = membus

	meanMemDiff = np.average(values)
	stdMemDiff = np.std(values)
	memSense = meanMemDiff <= 0.925 if stdMemDiff < 0.1 else meanMemDiff <= 0.8

	print "\tMemory%s\t: MEAN: %.3f STD: %.3f" % ("*" if memSense else " ", meanMemDiff, stdMemDiff)

	if cacheSense:
		if memSense:
			classified['ca-bw'].append(benchmark)
		else:
			classified['ca'].append(benchmark)
	else:
		if memSense:
			classified['bw'].append(benchmark)
		else:
			classified['co'].append(benchmark)		


# Sort classifications and dump to console
for group in classified:
	print "%s:" % group
	classified[group].sort()
	for benchmark in classified[group]:
		print "\t%s" % benchmark

# Write benchmarks to latex table
f = open(path.join(args.out, 'benchmarks.tex'), 'w')
f.write("\\begin{table}[ht]\n")
f.write("\\centering\n")
f.write("\\begin{tabular}{llll}\n")
f.write("\\toprule\n")
f.write("\\bf{Cache} & \\bf{Bandwidth} & \\bf{Cache \\& Bandwidth} & \\bf{Compute} \\\\ \\hline\n")

for i in range(0, max([len(classified[group]) for group in classified])):
	ca = classified["ca"][i] if i < len(classified["ca"]) else "\t"
	bw = classified["bw"][i] if i < len(classified["bw"]) else "\t"
	cabw = classified["ca-bw"][i] if i < len(classified["ca-bw"]) else "\t"
	co = classified["co"][i] if i < len(classified["co"]) else "\t"

	f.write("%s\t& %s\t& %s\t& %s\t\\\\ \n" % (ca, bw, cabw, co))

f.write("\\bottomrule\n")
f.write("\\end{tabular}\n")
f.write("\\caption{Benchmark Classifications}\n")
f.write("\\label{tbl:benchmarks_workloads:benchmark_classification}\n")
f.write("\\end{table}\n")
f.close()

import random
import math
from itertools import permutations

print ""
print "Workloads:"

def randomWorkload(pool, size):
	workload = []

	while len(workload) < size:
		benchmark = pool[random.randint(0, len(pool)-1)]
		if benchmark not in workload:
			workload.append(benchmark)

	return workload

def createWorkloads(size):
	tex = open(path.join(args.out, "workloads-%d.tex" % size), 'w')
	tex.write("\\begin{table}[ht]\n")
	tex.write("\\centering\n")
	tex.write("\\tiny\n")
	tex.write("\\resizebox{\columnwidth}{!}{%\n")
	tex.write("\\begin{tabular}{|r|r|llll|}\n")
	tex.write("\\hline\n")
	tex.write("Group & Workload & Benchmarks & & & \\\\ \\hline\n")


	# Generate benchmarks:
	result = {}
	groups = ['ca', 'bw', 'ca-bw', 'co', 'ra'] if size == 4 else [ 'ra' ]
	for group in groups:

		count = 5 if group in ['ca', 'ca-bw'] else 10
		if group == 'ra':
			pool = classified['ca']+classified['bw']+classified['ca-bw']+classified['co']
			count = 20 if size == 4 else 10
		else:
			pool = classified[group]

		workloads = []
		done = False

		while not done:
			workloads = []
			cover = []
			while len(workloads) < count:				
				permuation = randomWorkload(pool, size)

				# Check if the workload already exists
				found = False
				for workload in workloads:
					if len(set(workload) & set(permuation)) == len(workload):
						found = True

				if not found:
					workloads.append(permuation)					
					for workload in permuation:
						cover.append(workload)

			if group == 'ra' or len(set(classified[group])) == len(set(cover)):
				done = True

		first = True
		number = 0

		print "Group: %s" % group
		i = 0
		for workload in workloads:
			print "\t%s%d-%02d: %s" % (group, len(workload), i, '-'.join(workload))
			i += 1

			## Print group composition
			if group == 'ra':
				counters = {'ca': 0, 'bw': 0, 'ca-bw': 0, 'co': 0}
				for benchmark in workload:
					for key in classified.keys():
						if benchmark in classified[key]:
							counters[key] += 1
				print "\t\t Comp: ca %02d, bw %02d, cabw %02d, co %02d" % (counters['ca'], counters['bw'], counters['ca-bw'], counters['co'])


			header = "\t\t\t" if not first else "\\textbf{%s}\t" % group
			name = "%s%d-%d" % (group.replace('-', ''), size, number)

			i = 0
			while i < len(workload):
				tex.write("%s & %s\t & %s \\\\ \n" % (header, name, ' & '.join(workload[i:(i+4)])))
				header = name = ""
				i = i + 4
			if len(workload) > 4:				
				tex.write(" & & & & &  \\\\ \n")

			number += 1
			first = False

	tex.write("\\hline\n")
	tex.write("\\end{tabular}%\n")
	tex.write("} \n")
	tex.write("\\caption{%d-core workloads}\n" % size)
	tex.write("\\label{tbl:benchmark_workloads:%d-workloads}\n" % size)
	tex.write("\\end{table}\n")
	tex.close()

# Seed rng before each generate, that way if we change the number of workloads grenerated in one group it will not effect the following group(s)
random.seed("deadbeef01")
createWorkloads(4)

random.seed("deadbeef02")
createWorkloads(8)

random.seed("deadbeef03")
createWorkloads(16)