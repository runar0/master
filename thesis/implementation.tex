\chapter{Implementation}
\label{cpt:implementation}

A total of 5 algorithms presented in chapter~\ref{cpt:algorithms} has been implemented in our simulation system; TADIP, DRRIP, UCP, PIPP, and PriSM.
This chapter shortly covers any assumption, simplifications, or modifications in our implementations.
If nothing is stated in this chapter, the implementation matches the theoretical description given earlier.

\section{DRRIP}
The authors of DRRIP specify that they use set dueling to selct wether SRRIP or BRRIP is the optimal algorithm.
We use the same algorithm as in TADIP to select duel sets, because the authors of DRRIP does not specify their selection algorithm.

\section{Auxiliary Tag Directory and UMON}

We have implemented a generic ATD as described in section~\ref{sec:algorithms:umon}.
The ATD supports both configurable dynamic sampling and full sampling.
While previous work has shown that the estimation error when using dynamic sampling with a sufficient number of sets~\cite{} is negligible, we still opted for full sampling in all our experiments.
By doing full sampling, we eliminate the error source caused by imperfect data and allow the focus of our experiment to be on the decisions made by the algorithm instead.
Of the algorithms using the ATD implementation, only PIPP is affected by this decision, this is covered further in the next section.

Based on the ATD implementation a common UMON implementation was done, based on the description in section~\ref{sec:algorithms:umon}.
The theoretical UMON implementation allows a core to be assigned zero ways, but because our simulator uses inclusive caches, we need to store at least one block per core.
To achive this we have modified the first two lines of the UMON allocation algorithm, as shown in~\ref{alg:algorithms:ucp}.
Algorithm~\ref{alg:implementation:umon} shows the modification that ensures that each core is assigned at least one way.
Several of the previous works also did this modification to support inclusive caches~\cite{Qureshi2006,Xie2009}

\begin{algorithm}[ht]
\caption{Snip: Modified UMON Lookahead Algorithm}
\label{alg:implementation:ucp}
\begin{algorithmic}[1]
\State $balance\gets N - cores $ /* Number of ways minus number of cores */
\State $allocations[i]\gets 1$Â  /* for each core $i$ */
\end{algorithmic}
\end{algorithm}

\section{PIPP}

In the original PIPP paper~\cite{Xie2009}, there are two conditions that cause an application to be marked as streaming; miss rate and miss count.
The original paper uses dynamic sampling in the ATDs while we use full sampling.
Because the miss count condition scaled badly with full sampling, it was removed in our experiments.
Additionally, the original paper used a miss limit of 0.125 as the classification limit.
However, using our workloads we observed that most benchmarks were always marked as streaming, and this caused poor performance.
As a result, we increased the value to the next power of two, 0.25.
This change resulted in most benchmarks switching between streaming and not streaming as expected.

In additional to PIPP, we have implemented a variation we named PIPP-min8.
This variation works exactly like the normal PIPP algorithm, except that the insertion policy always adds eight to every position.
A block from an application with one block allocated to it will be inserted at position 9 instead of 1.
This modification is intended to increase the lifetime of blocks inserted by PIPP to increase the hit rate.
This modification has been mentioned by previous works~\cite{Manikantan2012} as well.

\section{PriSM}

The original PriSM paper states that the eviction probabilities, $E_i$, for all cores should sum to 1~\cite{Manikantan2012}.
However, we discover that this is not the case, at least for the miss minimization algorithm.
Simply normalizing the eviction probabilities is not a viable solution, as one or more cores may have an eviction probability of 1, indicating that they are always the eviction target, while other cores have $E > 0$.
If we normalize, the core(s) with $E=1$ are not guaranteed to be selected as the eviction target breaking this assumption.
As a result, we use a compound victim selection algorithm;
\begin{enumerate}
\item If one or more cores have an eviction probability of 1 we choose a victim at random between these cores.
\item If no core has an eviction probability of one or the selected core has no blocks in the set; we select one of the cores with $0 < E < 1$.
\item If neither of the two selected cores has blocks in the set the algorithm selects a random block owned by a with $E > 0$ as in the original implementation does.
\end{enumerate}
This modification allows us to prioritize cores with $E = 1$, which is not doable by normalizing.