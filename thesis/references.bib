@article{Sutter2005,
abstract = {The biggest sea change in software development since the OO revolution is knocking at the door, and its name is Concurrency.},
author = {Sutter, H},
doi = {10.1002/minf.201100042},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/Sutter - The Free Lunch is Over.pdf:pdf},
issn = {18681751},
journal = {Dr. Dobb's Journal},
pages = {1--9},
title = {{The free lunch is over: A fundamental turn toward concurrency in software}},
url = {http://www.mscs.mu.edu/~rge/cosc2200/homework-fall2013/Readings/FreeLunchIsOver.pdf},
year = {2005}
}
@misc{Ho2014,
author = {Ho, Joshua and Chester, Brandon and Heinonen, Chris and Smith, Ryan},
booktitle = {http://www.anandtech.com/show/8554/the-iphone-6-review/3},
title = {{The iPhone6 Review}},
url = {http://www.anandtech.com/show/8554/the-iphone-6-review/3},
year = {2014}
}
@article{Hardavellas2004,
author = {Hardavellas, Nikolaos and Somogyi, Stephen and Wenisch, Thomas F and Wunderlich, Roland E and Chen, Shelley and Kim, Jangwoo and Falsafi, Babak and Hoe, James C and Nowatzyk, Andreas G},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardavellas et al. - 2004 - SIMFLEX A Fast , Accurate , Flexible Full-System Simulation Framework for Performance Evaluation of Server.pdf:pdf},
journal = {Performance Evaluation Review},
number = {4},
pages = {31--35},
title = {{SIMFLEX : A Fast , Accurate , Flexible Full-System Simulation Framework for Performance Evaluation of Server Architecture}},
volume = {31},
year = {2004}
}
@article{Suh2004,
author = {Suh, G. E. and Rudolph, L. and Devadas, S.},
doi = {10.1023/B:SUPE.0000014800.27383.8f},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suh, Rudolph, Devadas - 2004 - Dynamic Partitioning of Shared Cache Memory.pdf:pdf},
issn = {0920-8542},
journal = {The Journal of Supercomputing},
keywords = {cache partitioning,cmp and smt,shared caches},
month = apr,
number = {1},
pages = {7--26},
title = {{Dynamic Partitioning of Shared Cache Memory}},
url = {http://link.springer.com/10.1023/B:SUPE.0000014800.27383.8f},
volume = {28},
year = {2004}
}
@article{Pellauer2011,
author = {Pellauer, Michael and Adler, Michael and Kinsy, Michel and Parashar, Angshuman and Emer, Joel},
doi = {10.1109/HPCA.2011.5749747},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pellauer et al. - 2011 - HAsim FPGA-based high-detail multicore simulation using time-division multiplexing.pdf:pdf},
isbn = {978-1-4244-9432-3},
journal = {2011 IEEE 17th International Symposium on High Performance Computer Architecture},
month = feb,
pages = {406--417},
publisher = {Ieee},
title = {{HAsim: FPGA-based high-detail multicore simulation using time-division multiplexing}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5749747},
year = {2011}
}
@article{Genbrugge2010,
author = {Genbrugge, Davy and Eyerman, Stijn and Eeckhout, Lieven},
doi = {10.1109/HPCA.2010.5416636},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Genbrugge, Eyerman, Eeckhout - 2010 - Interval simulation Raising the level of abstraction in architectural simulation.pdf:pdf},
isbn = {978-1-4244-5658-1},
journal = {\ldots Computer Architecture ( \ldots},
month = jan,
pages = {1--12},
publisher = {Ieee},
title = {{Interval simulation: Raising the level of abstraction in architectural simulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5416636 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5416636},
year = {2010}
}
@article{Wilkes2001,
author = {Wilkes, Maurice V.},
doi = {10.1145/373574.373576},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/tr.2001.4.pdf:pdf},
issn = {01635964},
journal = {ACM SIGARCH Computer Architecture News},
number = {1},
pages = {2--7},
title = {{The memory gap and the future of high performance memories}},
volume = {29},
year = {2001}
}
@article{ARM2010,
author = {ARM},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/DDI0433B\_cortex\_a5\_r0p1\_trm.pdf:pdf},
keywords = {Cortex-A,Cortex-A5},
title = {{Cortex-A5}},
year = {2010}
}
@article{Yi2005,
abstract = { Due to the simulation time of the reference input set, architects often use alternative simulation techniques. Although these alternatives reduce the simulation time, what has not been evaluated is their accuracy relative to the reference input set, and with respect to each other. To rectify this deficiency, this paper uses three methods to characterize the reduced input set, truncated execution, and sampling simulation techniques while also examining their speed versus accuracy trade-off and configuration dependence. Finally, to illustrate the effect that a technique could have on the apparent speedup results, we quantify the speedups obtained with two processor enhancements. The results show that: 1) the accuracy of the truncated execution techniques was poor for all three characterization methods and for both enhancements, 2) the characteristics of the reduced input sets are not reference-like, and 3) SimPoint and SMARTS, the two sampling techniques, are extremely accurate and have the best speed versus accuracy trade-offs. Finally, this paper presents a decision tree which can help architects choose the most appropriate technique for their simulations.},
author = {Yi, J.J. and Kodakara, S.V. and Sendag, R. and Lilja, D.J. and Hawkins, D.M.},
doi = {10.1109/HPCA.2005.8},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/hpca2005.pdf:pdf},
isbn = {0-7695-2275-0},
issn = {1530-0897},
journal = {11th International Symposium on High-Performance Computer Architecture},
title = {{Characterizing and comparing prevailing simulation techniques}},
year = {2005}
}
@article{Jain2013,
author = {Jain, Tarush and Agrawal, Tanmay},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain, Agrawal - 2013 - The Haswell Microarchitecture - 4th Generation Processor.pdf:pdf},
number = {3},
pages = {477--480},
title = {{The Haswell Microarchitecture - 4th Generation Processor}},
volume = {4},
year = {2013}
}
@misc{SPECCPU2006,
author = {SPECCPU},
title = {{SPEC CPU 2006}},
url = {http://www.spec.org/cpu2006/},
urldate = {2014-11-18},
year = {2006}
}
@article{Binkert2011,
author = {Binkert, Nathan and Sardashti, Somayeh and Sen, Rathijit and Sewell, Korey and Shoaib, Muhammad and Vaish, Nilay and Hill, Mark D. and Wood, David a. and Beckmann, Bradford and Black, Gabriel and Reinhardt, Steven K. and Saidi, Ali and Basu, Arkaprava and Hestness, Joel and Hower, Derek R. and Krishna, Tushar},
doi = {10.1145/2024716.2024718},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Binkert et al. - 2011 - The gem5 simulator.pdf:pdf},
issn = {01635964},
journal = {ACM SIGARCH Computer Architecture News},
month = aug,
number = {2},
pages = {1},
title = {{The gem5 simulator}},
url = {http://dl.acm.org/citation.cfm?doid=2024716.2024718},
volume = {39},
year = {2011}
}
@book{Eeckhout2010,
abstract = {Performance evaluation is at the foundation of computer architecture research and development. Contemporary microprocessors are so complex that architects cannot design systems based on intuition and simple models only. Adequate performance evaluation methods are absolutely crucial to steer the research and development process in the right direction. However, rigorous performance evaluation is non-trivial as there are multiple aspects to performance evaluation, such as picking workloads, selecting an appropriate modeling or simulation approach, running the model and interpreting the results using meaningful metrics. Each of these aspects is equally important and a performance evaluation method that lacks rigor in any of these crucial aspects may lead to inaccurate performance data and may drive research and development in a wrong direction. The goal of this book is to present an overview of the current state-of-the-art in computer architecture performance evaluation, with a special emphasis on methods for exploring processor architectures. The book focuses on fundamental concepts and ideas for obtaining accurate performance data. The book covers various topics in performance evaluation, ranging from performance metrics, to workload selection, to various modeling approaches including mechanistic and empirical modeling. And because simulation is by far the most prevalent modeling technique, more than half the book's content is devoted to simulation. The book provides an overview of the simulation techniques in the computer designer's toolbox, followed by various simulation acceleration techniques including sampled simulation, statistical simulation, parallel simulation and hardware-accelerated simulation. Table of Contents: Introduction / Performance Metrics / Workload Design / Analytical Performance Modeling / Simulation / Sampled Simulation / Statistical Simulation / Parallel Simulation and Hardware Acceleration / Concluding Remarks},
author = {Eeckhout, Lieven},
isbn = {1608454681},
pages = {145},
publisher = {Morgan \& Claypool Publishers},
title = {{Computer Architecture Performance Evaluation Methods}},
url = {http://books.google.com/books?id=3dlcAQAAQBAJ\&pgis=1},
year = {2010}
}
@misc{CARD2015,
author = {CARD, NTNU},
title = {https://www.idi.ntnu.no/grupper/dm/start},
url = {https://www.idi.ntnu.no/grupper/dm/start},
year = {2015}
}
@inproceedings{Wang2014,
author = {Wang, Ruisheng and Chen, Lizhong},
booktitle = {MICRO-47},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/2014\_MICRO\_Futility Scaling.pdf:pdf},
pages = {12},
title = {{Futility Scaling : High-Associativity Cache Partitioning}},
year = {2014}
}
@article{Shivakumar2001,
abstract = {CACTI 3.0 is an integrated cache access time, cycle time, area, aspect ratio, and power model. By integrating all these models together users can have confidence that tradeoffs between time, power, and area are all based on the same assumptions and hence are mutually consistent. CACTI is intended for use by computer architects so they can better understand the performance tradeoffs inherent in different cache sizes and organizations. This report details enhancements to CACTI 2.0 that are included in CACTI 3.0. CACTI 3.0 includes modeling support for the area and aspect ratio of caches, caches with independently addressed banks, reduced sense-amp power dissipation, and other improvements to CACTI 2.0.},
author = {Shivakumar, Premkishore and Jouppi, Norman P},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/WRL-TR-2001.2.pdf:pdf},
journal = {Computer},
number = {2001/2},
title = {{CACTI 3.0: An Integrated Cache Timing, Power, and Area Model}},
url = {https://eprints.kfupm.edu.sa/29113/},
year = {2001}
}
@article{Olsen2014,
author = {Olsen, Runar Bergheim},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Olsen - 2014 - Comparison of Cycle-accurate Simulation and Analytical Modelling for Multi-core Memory System.pdf:pdf},
title = {{Comparison of Cycle-accurate Simulation and Analytical Modelling for Multi-core Memory System}},
year = {2014}
}
@article{Luk2005,
author = {Luk, Chi-keung and Cohn, Robert and Muth, Robert and Patil, Harish and Klauser, Artur and Wallace, Steven and Janapa, Vijay and Lowney, Geoff},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Luk et al. - 2005 - Pin Building Customized Program Analysis Tools.pdf:pdf},
isbn = {1595930566},
keywords = {and eventually detach,collect profiles,dynamic com-,instrumentation,program analysis tools,strument it,the application},
title = {{Pin : Building Customized Program Analysis Tools}},
year = {2005}
}
@article{Qureshi2007,
author = {Qureshi, Moinuddin K. and Jaleel, Aamer and Patt, Yale N. and Steely, Simon C. and Emer, Joel},
doi = {10.1145/1273440.1250709},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qureshi et al. - 2007 - Adaptive insertion policies for high performance caching.pdf:pdf},
isbn = {9781595937063},
issn = {01635964},
journal = {ACM SIGARCH Computer Architecture News},
keywords = {replacement,set dueling,set sampling,thrashing},
month = jun,
number = {2},
pages = {381},
title = {{Adaptive insertion policies for high performance caching}},
url = {http://portal.acm.org/citation.cfm?doid=1273440.1250709},
volume = {35},
year = {2007}
}
@article{Jaleel2008,
address = {New York, New York, USA},
author = {Jaleel, Aamer and Hasenplaugh, William and Qureshi, Moinuddin and Sebot, Julien and Steely, Simon and Emer, Joel},
doi = {10.1145/1454115.1454145},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaleel et al. - 2008 - Adaptive insertion policies for managing shared caches.pdf:pdf},
isbn = {9781605582825},
journal = {Proceedings of the 17th international conference on Parallel architectures and compilation techniques - PACT '08},
keywords = {cache partitioning,replacement,set dueling,shared cache},
pages = {208},
publisher = {ACM Press},
title = {{Adaptive insertion policies for managing shared caches}},
url = {http://portal.acm.org/citation.cfm?doid=1454115.1454145},
year = {2008}
}
@article{Jahre,
author = {Jahre, Magnus and Reissmann, Nico and Grovdahl, Christian},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jahre, Reissmann, Grovdahl - Unknown - A Quantitative Survey of Dynamic Shared Cache Partitioning Techniques.pdf:pdf},
pages = {1--5},
title = {{A Quantitative Survey of Dynamic Shared Cache Partitioning Techniques}}
}
@article{Moore1998,
abstract = {Moore, G. E. (1965). Cramming more components onto integrated circuits, Electronics, Volume 38, Number 8, April 19, 1965. Also available online from ftp://download. intel. com/research/silicon/moorespaper. pdf. Chicago},
author = {Moore, Gordon E.},
doi = {10.1109/JPROC.1998.658762},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/moore.pdf:pdf},
isbn = {1558605398},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {1},
pages = {82--85},
pmid = {21527652},
title = {{Cramming more components onto integrated circuits}},
volume = {86},
year = {1998}
}
@article{Zhan2014,
abstract = {Most chip-multiprocessors nowadays adopt a large shared last-level cache (SLLC). This paper is motivated by our analysis and evaluation of state-of-the-art cache management proposals which reveal a common weakness. That is, the existing alternative replacement policies and cache partitioning schemes, targeted at optimizing either locality or utility of co-scheduled threads, cannot deliver consistently the best performance under a variety of workloads. Therefore, we propose a novel adaptive scheme, called CLU, to interactively co-optimize the locality and utility of co-scheduled threads in thread-aware SLLC capacity management. CLU employs lightweight monitors to dynamically profile the LRU (least recently used) and BIP (bimodal insertion policy) hit curves of individual threads on runtime, enabling the scheme to co-optimize the locality and utility of concurrent threads and thus adapt to more diverse workloads than the existing approaches. We provide results from extensive execution-driven simulation experiments to demonstrate the feasibility and efficacy of CLU over the existing approaches (TADIP, NUCACHE, TA-DRRIP, UCP, and PIPP).},
author = {Zhan, Dongyuan and Jiang, Hong and Seth, Sharad C.},
doi = {10.1109/TC.2012.277},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/clu-tc-2014.pdf:pdf},
isbn = {0018-9340 VO  - 63},
issn = {00189340},
journal = {IEEE Transactions on Computers},
keywords = {Capacity management,chip multiprocessors,locality and utility co-optimization,shared last level caches},
number = {7},
pages = {1656--1667},
title = {{CLU: Co-optimizing locality and utility in thread-aware capacity management for shared last level caches}},
volume = {63},
year = {2014}
}
@article{Rolf2009,
author = {Rolf, Trent},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rolf - 2009 - Cache organization and memory management of the Intel Nehalem computer architecture.pdf:pdf},
journal = {University of Utah Computer Engineering},
title = {{Cache organization and memory management of the Intel Nehalem computer architecture}},
url = {http://rolfed.com/nehalem/nehalemPaper.pdf},
year = {2009}
}
@article{Qureshi2006,
annote = {UCP},
author = {Qureshi, MK and Patt, YN},
doi = {10.1109/MICRO.2006.49},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qureshi, Patt - 2006 - Utility-based cache partitioning A low-overhead, high-performance, runtime mechanism to partition shared caches.pdf:pdf},
isbn = {0-7695-2732-9},
issn = {1072-4451},
journal = {Proceedings of the 39th Annual IEEE/ACM \ldots},
month = dec,
pages = {423--432},
publisher = {Ieee},
title = {{Utility-based cache partitioning: A low-overhead, high-performance, runtime mechanism to partition shared caches}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4041865 http://dl.acm.org/citation.cfm?id=1194855},
year = {2006}
}
@article{Manikantan2012,
annote = {PriSM},
author = {Manikantan, R and Rajan, K and Govindarajan, R},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manikantan, Rajan, Govindarajan - 2012 - Probabilistic shared cache management (PriSM).pdf:pdf},
isbn = {9781467304764},
journal = {ACM SIGARCH Computer \ldots},
number = {c},
title = {{Probabilistic shared cache management (PriSM)}},
url = {http://dl.acm.org/citation.cfm?id=2337208},
volume = {00},
year = {2012}
}
@article{Carlson2011a,
abstract = {Two major trends in high-performance computing, namely, larger numbers of cores and the growing size of on-chip cache memory, are creating significant challenges for evaluating the design space of future processor architectures. Fast and scalable simulations are therefore needed to allow for sufficient exploration of large multi-core systems within a limited simulation time budget. By bringing together accurate high-abstraction analytical models with fast parallel simulation, architects can trade off accuracy with simulation speed to allow for longer application runs, covering a larger portion of the hardware design space. Interval simulation provides this balance between detailed cycle-accurate simulation and one-IPC simulation, allowing long-running simulations to be modeled much faster than with detailed cycle-accurate simulation, while still providing the detail necessary to observe core-uncore interactions across the entire system. Validations against real hardware show average absolute errors within 25\% for a variety of multi-threaded workloads; more than twice as accurate on average as one-IPC simulation. Further, we demonstrate scalable simulation speed of up to 2.0 MIPS when simulating a 16-core system on an 8-core SMP machine.},
author = {Carlson, Trevor E. and Heirmant, Wim and Eeckhout, Lieven},
institution = {ELIS Department Ghent University, Belgium},
journal = {2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
keywords = {Interval simulation,interval model,multi-core processor,performance modeling},
pages = {1--12},
publisher = {IEEE},
title = {{Sniper: Exploring the level of abstraction for scalable and accurate parallel multi-core simulation}},
year = {2011}
}
@article{Moscibroda2007,
author = {Moscibroda, Thomas and Mutlu, Onur},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moscibroda, Mutlu - 2007 - Memory Performance Attacks Denial of Memory Service in Multi-Core Systems Memory Performance Attacks Denial.pdf:pdf},
title = {{Memory Performance Attacks : Denial of Memory Service in Multi-Core Systems Memory Performance Attacks : Denial of Memory Service in Multi-Core Systems}},
year = {2007}
}
@article{Sanchez2010,
abstract = {The ever-increasing importance of main memory latency and bandwidth is pushing CMPs towards caches with higher capacity and associativity. Associativity is typically improved by increasing the number of ways. This reduces conflict misses, but increases hit latency and energy, placing a stringent trade-off on cache design. We present the zcache, a cache design that allows much higher associativity than the number of physical ways (e.g. a 64-associative cache with 4 ways). The zcache draws on previous research on skew-associative caches and cuckoo hashing. Hits, the common case, require a single lookup, incurring the latency and energy costs of a cache with a very low number of ways. On a miss, additional tag lookups happen off the critical path, yielding an arbitrarily large number of replacement candidates for the incoming block. Unlike conventional designs, the zcache provides associativity by increasing the number of replacement candidates, but not the number of cache ways. To understand the implications of this approach, we develop a general analysis framework that allows to compare associativity across different cache designs (e.g. a set-associative cache and a zcache) by representing associativity as a probability distribution. We use this framework to show that for zcaches, associativity depends only on the number of replacement candidates, and is independent of other factors (such as the number of cache ways or the workload). We also show that, for the same number of replacement candidates, the associativity of a zcache is superior than that of a set-associative cache for most workloads. Finally, we perform detailed simulations of multithreaded and multiprogrammed workloads on a large-scale CMP with zcache as the last-level cache. We show that zcaches provide higher performance and better energy efficiency than conventional caches without incurring the overheads of designs with a large number of ways.},
author = {Sanchez, Daniel and Kozyrakis, Christos},
doi = {10.1109/MICRO.2010.20},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/2010.zcache.micro.pdf:pdf},
isbn = {9780769542997},
issn = {10724451},
journal = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
pages = {187--198},
title = {{The zcache: Decoupling ways and associativity}},
year = {2010}
}
@article{Microsystems2007,
abstract = {The world's first true system on a chip},
author = {Microsystems, Sun},
file = {:C$\backslash$:/Users/RunarBergheim/Downloads/t2-14-ust2-uasuppl-draft-hp-ext-1537761.html:html},
number = {8},
pages = {1--2},
title = {{UltraSPARC T2 Processor}},
url = {papers2://publication/uuid/B3E36587-E5E1-4D88-A405-A41DADD6F3E3},
year = {2007}
}
@article{Wunderlich2003,
abstract = {Current software-based microarchitecture simulators are many orders of magnitude slower than the hardware they simulate. Hence, most microarchitecture design studies draw their conclusions from drastically truncated benchmark simulations that are often inaccurate and misleading. We present the sampling microarchitecture simulation (SMARTS) framework as an approach to enable fast and accurate performance measurements of full-length benchmarks. SMARTS accelerates simulation by selectively measuring in detail only an appropriate benchmark subset. SMARTS prescribes a statistically sound procedure for configuring a systematic sampling simulation run to achieve a desired quantifiable confidence in estimates. Analysis of 41 of the 45 possible SPEC2K benchmark/ input combinations show CPI and energy per instruction (EPI) can be estimated to within 3\% with 99.7\% confidence by measuring fewer than 50 million instructions per benchmark. In practice, inaccuracy in micro-architectural state initialization introduces an additional uncertainty which we empirically bound to \&amp;sim;2\% for the tested benchmarks. Our implementation of SMARTS achieves an actual average error of only 0.64\% on CPI and 0.59\% on EPI for the tested benchmarks, running with average speedups of 35 and 60 over detailed simulation of 8-way and 16-way out-of-order processors, respectively.},
author = {Wunderlich, R.E. and Wenisch, T.F. and Falsafi, B. and Hoe, J.C.},
doi = {10.1109/ISCA.2003.1206991},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wunderlich et al. - 2003 - SMARTS accelerating microarchitecture simulation via rigorous statistical sampling.pdf:pdf},
isbn = {0-7695-1945-8},
issn = {1063-6897},
journal = {30th Annual International Symposium on Computer Architecture, 2003. Proceedings.},
title = {{SMARTS: accelerating microarchitecture simulation via rigorous statistical sampling}},
year = {2003}
}
@inproceedings{Manikantan2011,
abstract = {The effectiveness of the last-level shared cache is crucial to the performance of a multi-core system. In this paper, we observe and make use of the DelinquentPC \&\#x2014; Next-Use characteristic to improve shared cache performance. We propose a new PC-centric cache organization, NUcache, for the shared last level cache of multi-cores. NUcache logically partitions the associative ways of a cache set into MainWays and DeliWays. While all lines have access to the MainWays, only lines brought in by a subset of delinquent PCs, selected by a PC selection mechanism, are allowed to enter the DeliWays. The PC selection mechanism is an intelligent cost-benefit analysis based algorithm that utilizes Next-Use information to select the set of PCs that can maximize the hits experienced in DeliWays. Performance evaluation reveals that NUcache improves the performance over a baseline design by 9.6\%, 30\% and 33\% respectively for dual, quad and eight core workloads comprised of SPEC benchmarks. We also show that NUcache is more effective than other well-known cache-partitioning algorithms.},
author = {Manikantan, R. and Rajan, Kaushik and Govindarajan, R.},
booktitle = {Proceedings - International Symposium on High-Performance Computer Architecture},
doi = {10.1109/HPCA.2011.5749733},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manikantan, Rajan, Govindarajan - 2011 - NUcache An efficient multicore cache organization based on next-use distance.pdf:pdf},
isbn = {9781424494323},
issn = {15300897},
pages = {243--253},
title = {{NUcache: An efficient multicore cache organization based on next-use distance}},
year = {2011}
}
@article{Jaleel2010,
address = {New York, New York, USA},
annote = {SRRIP, DRRIP},
author = {Jaleel, Aamer and Theobald, Kevin B. and Steely, Simon C. and Emer, Joel},
doi = {10.1145/1815961.1815971},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaleel et al. - 2010 - High performance cache replacement using re-reference interval prediction (RRIP).pdf:pdf},
isbn = {9781450300537},
journal = {Proceedings of the 37th annual international symposium on Computer architecture - ISCA '10},
keywords = {all or part of,is granted without fee,not,or hard copies of,permission to make digital,personal or classroom use,provided that copies are,replacement,scan resistance,shared cache,this work for,thrashing},
pages = {60},
publisher = {ACM Press},
title = {{High performance cache replacement using re-reference interval prediction (RRIP)}},
url = {http://portal.acm.org/citation.cfm?doid=1815961.1815971},
year = {2010}
}
@article{Thomadakis2011,
author = {Thomadakis, ME},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomadakis - 2011 - The architecture of the Nehalem processor and Nehalem-EP SMP platforms.pdf:pdf},
journal = {Resource},
keywords = {archy,cache memory hier-,cc-numa,core and uncore,global queue,integrated-memory controllers,intel64,local and remote memory,micro-architecture,nehalem,performance,superscalar processors},
title = {{The architecture of the Nehalem processor and Nehalem-EP SMP platforms}},
url = {http://guizhongyun.elastos.org/redmine/attachments/download/457/nehalem.pdf},
year = {2011}
}
@article{Xie2009,
annote = {PIPP},
author = {Xie, Yuejian and Loh, GH},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie, Loh - 2009 - PIPP promotioninsertion pseudo-partitioning of multi-core shared caches.pdf:pdf},
isbn = {9781605585260},
journal = {ACM SIGARCH Computer Architecture News},
keywords = {cache,contention,insertion,multi-core,promotion,sharing},
pages = {174--183},
title = {{PIPP: promotion/insertion pseudo-partitioning of multi-core shared caches}},
url = {http://dl.acm.org/citation.cfm?id=1555778},
year = {2009}
}
@article{Miller2010,
author = {Miller, Jason E and Kasture, Harshad and Kurian, George and Iii, Charles Gruenwald and Beckmann, Nathan and Celio, Christopher and Eastep, Jonathan and Agarwal, Anant},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller et al. - 2010 - Graphite A Distributed Parallel Simulator for Multicores.pdf:pdf},
number = {January},
title = {{Graphite : A Distributed Parallel Simulator for Multicores}},
year = {2010}
}
@article{Chen-Han2014,
author = {Chen-Han, TNJM and Sankaralingam, HK},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen-Han, Sankaralingam - 2014 - gem5, GPGPUSim, McPAT, GPUWattch, Your favorite simulator here Considered Harmful.pdf:pdf},
journal = {research.cs.wisc.edu},
title = {{gem5, GPGPUSim, McPAT, GPUWattch," Your favorite simulator here" Considered Harmful}},
url = {http://research.cs.wisc.edu/vertical/papers/2014/wddd-sim-harmful.pdf},
year = {2014}
}
@article{Hamerly2005,
author = {Hamerly, Greg and Perelman, Erez},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamerly, Perelman - 2005 - SimPoint 3.0 Faster and More Flexible Program Phase Analysis.pdf:pdf},
journal = {Journal of Instruction-Level Parallelism},
number = {7},
pages = {1--28},
title = {{SimPoint 3.0: Faster and More Flexible Program Phase Analysis}},
url = {http://cseweb.ucsd.edu/~calder/papers/JILP-05-SimPoint3.pdf},
volume = {7},
year = {2005}
}
@article{Hamerly2004,
author = {Hamerly, Greg and Perelman, Rez and Calder, Bard},
file = {:C$\backslash$:/Users/RunarBergheim/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hamerly, Perelman, Calder - 2004 - How to use simpoint to pick simulation points.pdf:pdf},
journal = {ACM SIGMETRICS Performance \ldots},
pages = {25--30},
title = {{How to use simpoint to pick simulation points}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:No+Title\#0 http://dl.acm.org/citation.cfm?id=1054913},
year = {2004}
}
@book{Hennessy2012,
author = {Hennessy, John L and Patterson, David A},
publisher = {Elsevier},
title = {{Computer architecture: a quantitative approach}},
year = {2012}
}
