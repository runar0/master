
\section{Cache Partition}
\label{sec:results:cache_partition}

This section describes an experiment that will compare the various implemented cache partitioning algorithms both against LRU and against each other.
When executing this experiment, we utilize the base system configuration as previously detailed in table~\todo{ref}.
The L2 cache size is set to 128k per core, and the L3 cache size is set to 4MB, 8MB or 16MB for respectively 4-, 8- and 16-core workloads.
Each workload is simulated on the system until all benchmarks in that workload have completed at least once. 
The first time a benchmark completes we store its statistics.
After completion, a benchmark will restart until all other benchmarks have completed at least once.
We generate reference statistics for each benchmark a executing it on a single core private mode run.
In private mode, we use the same system with only a single core, with a 128k L2 and 4MB L3.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-stp-0128k-0100-avg}
        \caption{STP}
        \label{fig:results:base:avg:stp}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-hms-0128k-0100-avg}
        \caption{HMS}
        \label{fig:results:base:avg:hms}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-mpki-0128k-0100-avg}
        \caption{mpki}
        \label{fig:results:base:avg:mpki}
    \end{subfigure}
    \caption{Average STP, HMS and mpki relative to LRU for all workloads, grouped by number of cores.}
    \label{fig:results:base:avg}
\end{figure}

Figure~\ref{fig:results:base:avg:stp} shows the average speedup of all workloads grouped by workload size.
We observe that most of the implemented algorithms perform close to LRU for the four core workloads.
UCP gives the best speedup of 2.1\% while PIPP performs badly with a 2.4\% performance decrease. 
The modified version of PIPP, PIPP-min8, performs as good as LRU.
When considering the harmonic mean of speedups as shown in figure~\ref{fig:results:base:avg:hms} we observe that all algorithms perform as good or better than LRU.  
Most noticably is PIPP which in terms of HMS is equal to LRU.\todo{Explain what this indicates}
Figure~\ref{fig:results:base:avg:mpki} shows L3 cache misses, and as expected there is a significant increase, 20\%, in misses for PIPP compared to LRU, which explains the bad performance. 
The modified PIPP algorithm has a lower increase of 6.7%.
UCP, which is the highest performer in terms of STP and HMS, gives the third highest miss increase at 3.2\% more misses than LRU. 
This increase could be because UCP detects applications with high access frequency but low utility and allocates only a few blocks to those while allocating more blocks to applications with higher utility but possible lower access frequency.
The misses saved by the low access high utility applications may not weight up for the increased misses in the high-frequency ones. 
Hence, we observe a total increase in misses.
We could still see a performance benefit as the high utility applications now may execute with fewer misses.
In this same case, LRU would have favored the high access frequency one.

With increasing core count, we increase the size of the L3 cache, but the associativity is unchanged.
As a result, even more cores have to share the 32 blocks in each set.
For some algorithms, especially PIPP, this increased cache set pressure significantly degrades performance.
At 8-cores, PIPP has a 7.2\% performance decrease measured in STP compared to LRU.
The modified PIPP-min8 outperforms PIPP, and even slightly outperforms LRU by 2.2\%, in the same situation.
This is an indication that rows inserted by PIPP does not stay in the cache for long enough to see much re-use.
The modified algorithm seems to counteract this problem by inserting with an offset of 8 blocks higher than normal PIPP.
In the 16-core case, this effect is even more visible, with PIPP performing 45\% worse than LRU measured in STP and PIPP-min8 at only 7.6\% worse than LRU.
DRRIP and UCP, the two best performers in the 4-core case, continues to perform well for both 8- and 16-cores.
UCP beating LRU by 5.7\% and 6.9\% measured in STP in 8- and 16-core workloads, and DRRIP at 1.8\% and 2.6\%.
TADIP and PriSM, which both perform equally to LRU in the 4-core case, lose some traction when core count increases.
TADIP performs equal to LRU for 8-cores, but 3.6\% slower for 16-cores.
PriSM cannot keep up for more than 4-cores, and performs 4.7\% and 7.6\% slower for 8- and 16-cores.
We do however not that none of them increased misses, which is a good result considering they target miss-minimization.
This is an important result, showing that miss minimization does not imply speedup. 
Especially considering that UCP can cause a speedup while having as many or more misses as LRU.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.6\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-stp-0128k-0100-4-avg}
        \caption{STP}
        \label{fig:results:base:4-avg:stp}
    \end{subfigure}
    \begin{subfigure}[b]{0.6\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-hms-0128k-0100-4-avg}
        \caption{HMS}
        \label{fig:results:base:4-avg:hms}
    \end{subfigure}
    \begin{subfigure}[b]{0.6\textwidth}
        \includegraphics[width=\textwidth]{figures/results/speedup/avg-mpki-0128k-0100-4-avg}
        \caption{mpki}
        \label{fig:results:base:4-avg:mpki}
    \end{subfigure}
    \caption{Average STP, HMS and mpki relative to LRU for all 4 core workload groups.}
    \label{fig:results:base:4-avg} 
\end{figure}

Our 4-core workloads divided into five groups, where four of the groups contain benchmarks with a specific characteristic.
Each group and the properties of their benchmarks are covered in section~\todo{ref to benchmarks-workloads}
Figure~\ref{fig:result:base:4-avg} shows average STP, HMS and mpki normalized to LRU for these five groups.
Exploring the result from each of these groups individually is useful as it will show how various algorithms react to specific workload characteristics.

Bandwidth bound workloads contain benchmarks that do not benefit from increased cache space.
These are benchmarks with mainly streaming access patterns. 
As expected the figure confirms that none of the algorithms can significantly improve performance compared to LRU.
As seen in figure~\ref{avg:result:base:4-avg:mpki} UCP causes 3\% more misses than LRU, and in return increases STP by 0.9\% compared to LRU.
We expect this is because UCP detects phases in the benchmark access patterns where they stray from the streaming pattern and prioritizes those benchmarks during that phase.
While PIPP in theory also should be able to detect such changes, our result shows it does not.
A possible explanation to this is that PIPP uses both utility and streaming flags.
While an application may periodically have increased utility causing UCP to prioritize it, PIPP might still consider it as streaming due to its history and ignore the increased utility.

Cache bound workloads contain benchmarks that are sensitive to changes in available cache space.
Our results from these workloads show two main trends.
First LRU performs well, and none of the other algorithms increases performance or significantly reduce misses.
Secondly, UCP and PIPP, the two algorithms that perform way partitioning, both reduce performance and cause a significant miss increase. 
While TADIP and DRRIP, which both mimic LRU and PriSM that performs a variant of block level partitioning performs as good as LRU in terms of performance.
PriSM, however, causes a small increase in misses.

The performance of compute bound workloads are expected to be unaffected by the partitioning algorithm. 
Our results also what our results supports this assumption, with the exception of PIPP, which again causes increased misses and, as a result, a slight performance decrease.
Again PIPP-min8 seems to remedy this, pointing to blocks having to short lifetimes in a PIPP managed cache to see many hits.

Both cache and bandwidth bound workloads and the random workloads show results that concur with the overall averages discussed earlier.
One interesting fact to note is that both versions of PIPP and UCP are equally good and also the best performers when measuring in HMS.\todo{discuss why this could be}

