
\chapter{Cache Management Algorithms}
\label{cpt:algorithms}


A cache management algorithm manages the storage space in a cache.
It decides where to store new data blocks and which of the existing blocks are evicted to make room for new blocks.
Some algorithms are thread-aware and geared towards shared caches.
Others are thread-agnostic and work both for shared and private caches.
Some have advanced optimization goals such as \gls{qos} while others use simpler metrics like miss minimization.
Algorithms proposed for shared caches may in general be divided into two groups, those that explicitly divide storage space between cores sharing the cache and those that do not.
The term cache replacement algorithm is often used to describe algorithms that do not divide the storage space while the term cache partitioning algorithm describe algorithms that do divide the space.
Throughout this paper, we will use the two terms interchangeably.

The field of cache management is well researched, and there exists a large number of proposed algorithms.
In this thesis, we present a few recently proposed algorithms and compare their performance.
We will also present \gls{lru}, an algorithm that is thread-agnostic and widely used both in private and shared caches today.
Table~\ref{tbl:algorithms} lists the selected algorithms.
Only algorithms that optimize for fewer cache misses are included.
This metric is easy to measure and also makes it easy to compare the various algorithms.
Also, we only consider algorithms that target conventional caches, as they are designed in \glspl{cmp} today.
This limitation makes the comparison of results from different algorithms easier.
Also, we avoid having to extend our simulator with a new cache type, which would be unfeasible given the time constraints of this thesis.

\begin{table}[thb]
\begin{tabular}{|p{1.4cm}|p{0.5cm}|p{0.8cm}|p{1.2cm}|p{1.2cm}|p{1.4cm}|p{1.2cm}|p{1.0cm}|}
\hline
\multicolumn{1}{|c|}{Name} & \multicolumn{1}{c|}{Year} & \multicolumn{1}{c|}{Thread} & \multicolumn{1}{c|}{Repl.} & \multicolumn{1}{c|}{Insert.} & \multicolumn{1}{c|}{Promo.} & \multicolumn{1}{c|}{Hardware}    & \multicolumn{1}{c|}{Partition}     \\
\multicolumn{1}{|c|}{}          & \multicolumn{1}{c|}{}          & \multicolumn{1}{c|}{aware}  & \multicolumn{1}{c|}{policy}      & \multicolumn{1}{c|}{policy}    & \multicolumn{1}{c|}{policy}    & \multicolumn{1}{c|}{overhead\footnotemark}  & \multicolumn{1}{c|}{}       \\ \hline
\gls{dip}                             & 2007                           & No                          & \gls{lru}                              & \gls{lip}/ \gls{bip}                        & Promote to \gls{mru}            & 1 counter, set dueling    & No            \\ \hline
\gls{tadip}                           & 2008                          & Yes                         & \gls{lru}                              & \gls{lip}/ \gls{bip}                        & Promote to \gls{mru}            & 1 counter per core, set dueling  & No          \\ \hline
\gls{drrip}                           & 2010                          & Yes                         & \gls{lru} approx.                      & \gls{srrip}/ \gls{brrip}                    & Stepwise promotion            & 1 counter per core, set dueling  & No          \\ \hline
\gls{nucache}                         & 2011                         & No                          & \gls{lru} + DeliWays     & \gls{lip}                            & Promote to \gls{mru}                 & NUTrack                            & No    \\ \hline
\gls{ucp}                             & 2006                           & Yes                         & Per core \gls{lru}                     & \gls{lip}                            & Promote to \gls{mru}                 & \gls{umon}, 1 \gls{atd} per core   & Yes                \\ \hline
\gls{pipp}                            & 2009                           & Yes                         & \gls{lru}                              & Utility position               & Stepwise promotion            & \gls{umon}, 1 \gls{atd} per core, random generator & Yes \\ \hline
\gls{prism}                           & 2012                           & Yes                         & Per core \gls{lru}                  & \gls{lip}                            & Promote to \gls{mru}                 & 1 \gls{atd} per core, random generator                       & Yes  \\ \hline
\gls{clu}                             & 2014                           & Yes                         & \gls{lru}                              & \gls{lip}/ \gls{bip}                        & Promote to \gls{mru}/ Skip            & \gls{umon} \~3 \glspl{atd} per core                & Yes  \\ \hline
\end{tabular}
\caption{Overview of Cache Management Algorithms.}
\label{tbl:algorithms}
\end{table}
\clearpage

It is possible to divide all algorithms included in this evaluation into three distinct policies:
\begin{itemize}
\item The replacement policy specifies which block a cache set evicts when inserting a new block into that set.
\item The insertion policy specifies the state of new blocks after insertion into the cache set.
\item The promotion policy specifies how the state of a block changes following an access from a processor core.
\end{itemize}
In the following sections, we will explain how each of the selected cache partitioning algorithms work, with an emphasis on this division to make comparisons easier.

\section{Cache Replacement Algorithms}
This section covers cache replacement algorithms, or algorithms that do not explicitly divide the available cache space between cores.


\footnotetext{Simplified hardware overhead compared to an \gls{lru} managed cached.}

\input{algorithms/LRU.tex}
\input{algorithms/DIP.tex}
\input{algorithms/TADIP.tex}
\input{algorithms/DRRIP.tex}
\input{algorithms/NUCache.tex}

\section{Cache Partitioning Algorithms}
This section covers cache partitioning algorithms.
In contrast to the replacement algorithms, these algorithms explicitly assign a set number of blocks in each cache set to each core.

\input{algorithms/UCP.tex}
\input{algorithms/PIPP.tex}
\input{algorithms/PriSM.tex}
\input{algorithms/CLU.tex}